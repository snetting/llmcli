**llmcli --- Shell Task Automation with LLM Assistance**

llmcli is a command-line tool that uses a locally or remotely hosted Large Language Model (LLM) to:

-   Answer user questions

-   Automate shell tasks by generating and executing commands step by step

-   Summarize the results of those tasks after execution

It communicates with an OpenAI-compatible API endpoint (tested with OpenWebUI/Ollama) and can operate in interactive or non-interactive modes.

* * * * *

**Configuration**

The following settings can be configured using environment variables, allowing you to share or deploy the script without hardcoded secrets:

-   `LLMCLI_API`: URL of the API endpoint\
    Default: `http://dogbox.local:4000/api/chat/completions`

-   `LLMCLI_API_TOKEN`: API token for authentication\
    Default: `sk-7db43b229f614481b413ceba13a1f186`

-   `LLMCLI_MODEL`: The LLM model to use\
    Default: `qwen-general4b`

-   `LLMCLI_COLLECTION_ID`: Optional retrieval collection ID\
    Default: *(empty)*

Example usage in your shell:


`export LLMCLI_API="http://localhost:11434/v1/chat/completions
export LLMCLI_API_TOKEN="your-token"
`export LLMCLI_MODEL="mistral"`

* * * * *

**Command-line Options**

-   `-s` or `--shell-task`\
    Automate a shell task using the LLM to generate and explain commands.

-   `-f` or `--file`\
    Include the contents of a file as part of the prompt for context.

-   `-v`\
    Show basic status messages (e.g. "Thinking...").

-   `-vv`\
    Also show the LLM's reasoning steps.

-   `-vvv`\
    Also display each generated command and its output.

-   `-i`\
    Interactive mode. Prompts you to confirm each command before it's run.

-   `-h`\
    Display help and usage instructions.

* * * * *

**Usage**

Ask a question:

`llmcli "How do I configure rsync over SSH?"`

Ask a question with file context:

`llmcli -f config.txt "What does this configuration do?"`

- or - 

`cat config.txt | llmcli "What does this configuration do?"`

To interactively create four 4KB files, with explanations and confirmations before each step:

`llmcli -i -s "Create 4 empty files of 4KB each"`

Run an automated shell task (WARNING: no interaction / confirmations):

`llmcli -s "Set up a local HTTP server using Python"`


* * * * *


**Important Warning and Disclaimer**

This tool can execute arbitrary shell commands generated by an AI.

**If you use llmcli without the `-i` (interactive) option, commands are executed immediately without user confirmation.** This can be risky, especially if:

-   You run the script with elevated permissions (e.g. `sudo`)

-   The LLM misinterprets your request or generates destructive commands

**Always use the `-i` flag unless you're completely confident.**\
NEVER run the script as root unless you are fully aware of the risks.

* * * * *

**About the Code**

This script was partially written using a language model (LLM).\
While care has been taken to review its logic, users are strongly encouraged to read and understand the code before trusting it with system-level tasks.

* * * * *

**License and Liability**

This tool is provided without warranty or guarantees.\
The author assumes **no responsibility** for any damage, data loss, or unintended side effects caused by use of this tool.\
Use at your own risk.

* * * * *

**Example**

To create four 4KB files safely, with explanations and confirmations before each step:

`llmcli -i -s "Create 4 empty files of 4KB each"`

* * * * *

Use wisely. Test safely.
